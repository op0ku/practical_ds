{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a36438b",
   "metadata": {},
   "source": [
    "# AUTOMATE DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "556754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from scipy import stats\n",
    "import random\n",
    "\n",
    "import re\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype\n",
    "from datetime import datetime\n",
    "from typing import Union, Optional\n",
    "import phonenumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf4204",
   "metadata": {},
   "source": [
    "### 1. Basic Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e59e9d",
   "metadata": {},
   "source": [
    "Using **df.info()** provides:  \n",
    "- data type (dataFrame)\n",
    "- number of rows\n",
    "- number of columns\n",
    "- number of values not null in columns\n",
    "- columns type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7aae6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hr_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50330ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               18 non-null     int64  \n",
      " 1   name             17 non-null     object \n",
      " 2   age              17 non-null     float64\n",
      " 3   gender           18 non-null     object \n",
      " 4   email            18 non-null     object \n",
      " 5   income           17 non-null     float64\n",
      " 6   job_title        18 non-null     object \n",
      " 7   department       18 non-null     object \n",
      " 8   start_date       18 non-null     object \n",
      " 9   education        18 non-null     object \n",
      " 10  customer_rating  16 non-null     float64\n",
      " 11  comments         17 non-null     object \n",
      " 12  phone_number     18 non-null     object \n",
      " 13  country          18 non-null     object \n",
      " 14  purchase_amount  18 non-null     object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9b6056",
   "metadata": {},
   "source": [
    "Check for:\n",
    "- Duplicated rows\n",
    "- number of unique values in columns\n",
    "- columns with missing values and percentage of missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b95e4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_characteristics(data: Union[pd.DataFrame, pd.Series]) -> None:\n",
    "    \"\"\"\n",
    "    Analyzes and prints key characteristics of a pandas DataFrame or Series.\n",
    "\n",
    "    This function calculates and displays the following information:\n",
    "    - The total number of duplicate rows/values.\n",
    "    - The memory usage of the DataFrame/Series in megabytes (MB).\n",
    "    - The number of unique values for each column (if a DataFrame) or for the Series itself.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame | pd.Series): The pandas DataFrame or Series to analyze.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value; it prints the characteristics\n",
    "              directly to the console.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the input `data` is not a pandas DataFrame or Series.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        raise TypeError(\"Input 'data' must be a pandas DataFrame or Series.\")\n",
    "\n",
    "    print(\"\\n--- Data Characteristics ---\")\n",
    "\n",
    "    # Calculate and print the number of duplicate rows/values\n",
    "    print(f\"\\nDuplicates: {data.duplicated().sum()}\")\n",
    "\n",
    "    # Return memory usage in MB\n",
    "    memory_mb = data.memory_usage(deep=True).sum() / (1024**2)\n",
    "    print(f\"\\nMemory Usage: {memory_mb:.4f} MB\") # Formatted to 4 decimal places\n",
    "\n",
    "    # Return number of unique values\n",
    "    print(f\"\\nUnique Values:\\n {data.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b715f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Characteristics ---\n",
      "\n",
      "Duplicates: 3\n",
      "\n",
      "Memory Usage: 0.0135 MB\n",
      "\n",
      "Unique Values:\n",
      " id                 15\n",
      "name               13\n",
      "age                14\n",
      "gender              6\n",
      "email              15\n",
      "income             14\n",
      "job_title          14\n",
      "department          9\n",
      "start_date         14\n",
      "education          12\n",
      "customer_rating    12\n",
      "comments           14\n",
      "phone_number       14\n",
      "country             8\n",
      "purchase_amount    15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_characteristics(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f6f5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_check(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies columns containing any null values (NaN or None) in a dataframe,\n",
    "    calculates the total count of missing values, and their percentage\n",
    "    of missingness.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame to check for missing values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with three columns:\n",
    "                      - 'column': The name of the column with missing values.\n",
    "                      - 'missing_count': The total number of missing values in that column.\n",
    "                      - 'missing_percentage': The percentage of missing values (0.0 to 1.0).\n",
    "                      Returns an empty DataFrame if no missing values are found or\n",
    "                      if the input DataFrame is empty.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Check if Dataframe is empty\n",
    "    if data.empty:\n",
    "        print(\"Empty DataFrame. No missing values to check!\")\n",
    "    \n",
    "    # Get count of missing values for each column in dataframe\n",
    "    missing_counts = data.isnull().sum()\n",
    "    missing_counts = missing_counts[missing_counts.values > 0]\n",
    "    # Get percentage of missing values\n",
    "    missing_percentages = round((missing_counts / len(data)), 2)\n",
    "\n",
    "    # Make dataframe for columns with missing values\n",
    "    missing_summary = pd.DataFrame({'column': missing_counts.index,\n",
    "                                    'missing_count': missing_counts.values,\n",
    "                                    'missing_percentage': missing_percentages.values})\n",
    "    \n",
    "    # Print summary\n",
    "    if missing_summary.empty:\n",
    "        print(\"No column has missing value(s) in this dataframe\")\n",
    "    \n",
    "    return missing_summary\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f3ad63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>income</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>customer_rating</td>\n",
       "      <td>2</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column  missing_count  missing_percentage\n",
       "0             name              1                0.06\n",
       "1              age              1                0.06\n",
       "2           income              1                0.06\n",
       "3  customer_rating              2                0.11\n",
       "4         comments              1                0.06"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_check(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a79317",
   "metadata": {},
   "source": [
    "### 2. General Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a3243",
   "metadata": {},
   "source": [
    "Perform the following:\n",
    "- remove duplicates from data\n",
    "- drop completely empty rows from data\n",
    "- drop columns with more than 40% missing data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f389f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\"\n",
    "    Clean a dataset by removing duplicated or empty rows if available,\n",
    "    dropping columns with high percentage of misssing data points.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned dataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- Initiating data cleaning process ---\")\n",
    "    clean_data = data.copy()\n",
    "\n",
    "    # Drop duplicated rows if available\n",
    "    if any(clean_data.duplicated()):\n",
    "        initial_rows = len(clean_data)\n",
    "        clean_data = clean_data.drop_duplicates()\n",
    "        rows_after_drop = len(clean_data)\n",
    "        print(f\"\\n\\nDropped {initial_rows - rows_after_drop} duplicated row(s).\\n\")\n",
    "    else:\n",
    "        print(\"\\n\\nNo duplicated rows found.\\n\")\n",
    "\n",
    "    # Drop completely empty rows\n",
    "    empty_rows_count = clean_data.isnull().all(axis=1).sum()\n",
    "\n",
    "    if empty_rows_count > 0:\n",
    "        clean_data = clean_data.dropna(how='all')\n",
    "        print(f\"Dropped {empty_rows_count} completely empty row(s).\\n\")\n",
    "    else:\n",
    "        print(\"No completely empty rows found.\\n\")\n",
    "    \n",
    "    # Drop columns with > 40% of data points missing\n",
    "    pct_missing = clean_data.isnull().sum() / len(clean_data)\n",
    "    columns_to_drop = pct_missing[pct_missing > .4].index.tolist()\n",
    "    \n",
    "    if columns_to_drop:\n",
    "        clean_data = clean_data.drop(columns_to_drop, axis=1)\n",
    "        dropped_columns_info = \", \".join([\n",
    "            f\"{col} ({round(pct_missing[col]*100, 2)}%)\"\n",
    "            for col in columns_to_drop\n",
    "        ])\n",
    "        print(f\"Dropped columns with more than 40% missing values: {dropped_columns_info}%\\n\\n\")\n",
    "    else:\n",
    "        print(\"No columns found with more than 40% missing values.\\n\\n\")    \n",
    "\n",
    "    print(\"--- Data cleaning process complete ---\")\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9bd5b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initiating data cleaning process ---\n",
      "\n",
      "\n",
      "Dropped 3 duplicated row(s).\n",
      "\n",
      "No completely empty rows found.\n",
      "\n",
      "No columns found with more than 40% missing values.\n",
      "\n",
      "\n",
      "--- Data cleaning process complete ---\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eaf25d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15 entries, 0 to 14\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               15 non-null     int64  \n",
      " 1   name             14 non-null     object \n",
      " 2   age              14 non-null     float64\n",
      " 3   gender           15 non-null     object \n",
      " 4   email            15 non-null     object \n",
      " 5   income           14 non-null     float64\n",
      " 6   job_title        15 non-null     object \n",
      " 7   department       15 non-null     object \n",
      " 8   start_date       15 non-null     object \n",
      " 9   education        15 non-null     object \n",
      " 10  customer_rating  13 non-null     float64\n",
      " 11  comments         14 non-null     object \n",
      " 12  phone_number     15 non-null     object \n",
      " 13  country          15 non-null     object \n",
      " 14  purchase_amount  15 non-null     object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 1.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98a481",
   "metadata": {},
   "source": [
    "### 2. Standardize Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea3a22",
   "metadata": {},
   "source": [
    "- convert string dates to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4831de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_datetime(data: pd.DataFrame) -> tuple[pd.DataFrame, list[str]]:\n",
    "    \"\"\"\n",
    "    Iterates through DataFrame columns, identifies potential date columns\n",
    "    based on keywords in their names, and attempts to convert them to datetime objects.\n",
    "    It handles mixed date formats and invalid entries.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        - pd.DataFrame: The DataFrame with identified date columns converted to datetime type.  \n",
    "        \n",
    "        - list: List of columns successfully converted to datetime.\n",
    "    \"\"\"\n",
    "    print(\"--- Initiating datetime standardization process ---\")\n",
    "    # Make copy of data\n",
    "    data = data.copy()\n",
    "\n",
    "    # Collect successfully convertd column(s)\n",
    "    columns_converted: list[str] = []\n",
    "    \n",
    "    for column in data.columns:\n",
    "            # Check if column  is string and its name contains an identifying keyword\n",
    "            if \"date\" in column.lower() and data[column].dtype == 'object':\n",
    "                print(f\"Attempting to convert '{column}' column from {data[column].dtype} to datetime type...\\n\")\n",
    "                try:\n",
    "                    # Perform conversion\n",
    "                    datetime_series = pd.to_datetime(data[column], format='mixed', errors='coerce')\n",
    "\n",
    "                    if is_datetime64_any_dtype(datetime_series) and not datetime_series.isnull().all():\n",
    "                        data[column] = datetime_series\n",
    "                        print(f\"'{column}' column is now of {data[column].dtype} type\\n\")\n",
    "                    \n",
    "                        # Report how much, if any values where coerced to NaT\n",
    "                        coerced = datetime_series.isnull().sum()\n",
    "                        if coerced > 0:\n",
    "                            print(f\"{coerced} invalid dates where coerced to NaT in '{column}' column\\n\")\n",
    "                        \n",
    "                        columns_converted.append(column)\n",
    "                        \n",
    "                        # Inform on whether any column(s) were converted\n",
    "                        if len(columns_converted) == 0:\n",
    "                            print(\"No columns matching identifying keyword(s) were found in the DataFrame to convert.\")\n",
    "                        else:\n",
    "                            print(f\"Datetime conversion complete for the following column(s):\")\n",
    "                            print(columns_converted)\n",
    "                except Exception as e:\n",
    "                     # Report if the dataframe itself has issue(s)\n",
    "                     print(f\"Error {e} occured while converting {column} column to date type\")\n",
    "    \n",
    "    print(\"\\n--- Datetime standardization process complete ---\")\n",
    "    return data\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "47c896f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type before standardizing\n",
    "df['start_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "adba28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initiating datetime standardization process ---\n",
      "Attempting to convert 'start_date' column from object to datetime type...\n",
      "\n",
      "'start_date' column is now of datetime64[ns] type\n",
      "\n",
      "Datetime conversion complete for the following column(s):\n",
      "['start_date']\n",
      "\n",
      "--- Datetime standardization process complete ---\n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "df_clean = standardize_datetime(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03b0ebab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['start_date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111802b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2019-03-15\n",
       "1    2020-01-10\n",
       "2    2018-05-20\n",
       "3    2017-11-05\n",
       "4    2021-02-28\n",
       "5    2019-08-12\n",
       "6    2020-07-15\n",
       "7    2020-01-10\n",
       "8    2022-04-18\n",
       "9    2021-01-15\n",
       "10   2015-09-30\n",
       "11   2018-12-05\n",
       "12   2022-02-10\n",
       "13   2017-06-22\n",
       "14   2019-11-18\n",
       "15   2022-04-18\n",
       "16   2018-12-05\n",
       "17   2020-07-15\n",
       "Name: start_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type after standardizing\n",
    "df['start_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccbae0f",
   "metadata": {},
   "source": [
    "- convert numeric strings to actual numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9e97577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_numeric(data: pd.DataFrame,\n",
    "                      exclude_keywords: list[str]=[\"phone\", \"date\"],\n",
    "                      ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Iterates through DataFrame columns, attempts to convert string-like\n",
    "    numeric values to actual numeric types, while skipping specified\n",
    "    keyword-containing columns and handling non-numeric strings.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame.\n",
    "        exclude_keywords (list): List of  keywords to detect in column names. These columns can be numeric, but do not have numeric value.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with applicable columns converted to numeric.\n",
    "    \"\"\"\n",
    "    print(\"--- Initiating string to numeric conversion process ---\\n\")\n",
    "    data = data.copy()\n",
    "    remove_symbols = [\"$\", \"€\", \"£\", \"¥\", \",\", \"%\"]\n",
    "\n",
    "    for column in data.columns:\n",
    "        # Check if column does not contain exclude keywords\n",
    "        if any(keyword not in column.lower() for keyword in exclude_keywords):\n",
    "            if data[column].dtype == 'object':\n",
    "                try:\n",
    "                    column_to_numeric = (\n",
    "                        data[column].str.strip()\n",
    "                                    .str.replace(r\"^\\((.*)\\)$\", r\"-\\1\", regex=True) # handle negative values in parentheses\n",
    "                    )\n",
    "                    # Drop remove symbols from column\n",
    "                    for symbol in remove_symbols:\n",
    "                        column_to_numeric = column_to_numeric.str.replace(symbol, '')\n",
    "                    \n",
    "                    # Empty strings or whitespaces to NaN\n",
    "                    column_to_numeric = column_to_numeric.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "                    # Convert to numeric\n",
    "                    column_to_numeric = pd.to_numeric(column_to_numeric, errors='coerce')\n",
    "\n",
    "                    # Check if significant proportion of data has been converted to numeric\n",
    "                    original_not_nan_count = data[column].dropna().shape[0]\n",
    "                    converted_not_nan_count = column_to_numeric.dropna().shape[0]\n",
    "\n",
    "                    if (original_not_nan_count > 0 and \n",
    "                        (converted_not_nan_count / original_not_nan_count) > .5):\n",
    "                        # Add cleaned column to dataframe\n",
    "                        data[column] = column_to_numeric\n",
    "                        print(f\"\\n'{column}' column successfully converted to numeric\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"{e} has occured while converting {column} to numeric!\")\n",
    "            else:\n",
    "                try:\n",
    "                    # Ensure consistency of all numeric columns\n",
    "                    converted_numeric = pd.to_numeric(data[column], errors='coerce')\n",
    "\n",
    "                    # only update if conversion actually changed dtype or introduced NaNs\n",
    "                    if not is_numeric_dtype(data[column].dtype) or (is_numeric_dtype(data[column].dtype) and not converted_numeric.equals(data[column])):\n",
    "                        data[column] = converted_numeric\n",
    "                        print(f\"{column} column converted to consistent numeric type successfully.\")\n",
    "                    else:\n",
    "                        print(f\"'{column}' column is already of type {data[column].dtype}; no change needed.\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while attempting to standardize '{column}' (type {data[column].dtype}): {e}\")\n",
    "\n",
    "    print(\"\\n--- String to numeric conversion process complete ---\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ccfe340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['purchase_amount'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c2dd15e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initiating string to numeric conversion process ---\n",
      "\n",
      "'id' column is already of type int64; no change needed.\n",
      "'age' column is already of type float64; no change needed.\n",
      "'income' column is already of type float64; no change needed.\n",
      "'customer_rating' column is already of type float64; no change needed.\n",
      "\n",
      "'purchase_amount' column successfully converted to numeric\n",
      "\n",
      "--- String to numeric conversion process complete ---\n"
     ]
    }
   ],
   "source": [
    "df_clean = string_to_numeric(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c98c5d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['purchase_amount'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea02a2",
   "metadata": {},
   "source": [
    "### 4. Handle Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f6e46",
   "metadata": {},
   "source": [
    "- Standardize Phone Numbers (Based on Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4d88d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to assist standardize_phone function\n",
    "def _parse_and_format_phone(phone_str: str,\n",
    "                            region: str,\n",
    "                            output_format: phonenumbers.PhoneNumberFormat,\n",
    "                            strictly_validate: bool\n",
    "                            ) -> Union[str, pd.NA]:\n",
    "    \"\"\"\n",
    "    Helper function to parse, validate, and format a  phone number string.\n",
    "\n",
    "    Args:\n",
    "        phone_str (str): The phone number string to process.\n",
    "        region (str): Two-letter ISO 3166-1 country code to assume for phone numbers without a country code e.g.(\"US\", \"UK\").\n",
    "        output_format (phonenumbers.PhoneNumberFormat): Preferred output format for phone number.\n",
    "        strictly_validate (boolean): If True, performs strict validation on phone before formatting,\n",
    "                                     to ensure the phone actually is valid for the specified region.\n",
    "                                     If False, only checks whether phone is struturally possible before formatting.\n",
    "\n",
    "    Returns:\n",
    "        str | pd.NA: The formatted phone number string if valid, otherwise pd.NA.\n",
    "    \"\"\"\n",
    "    # Take care of NaN, non-strings or empty strings\n",
    "    if pd.isna(phone_str) or not isinstance(phone_str, str) or not phone_str.strip():\n",
    "        print(f\"'{phone_str}' is NA/empty/non-string. Returning NA.\")\n",
    "        return pd.NA\n",
    "    \n",
    "    try:\n",
    "        # Return phone as specified output if phone is actually correct and is valid for its region\n",
    "        parsed_phone = phonenumbers.parse(phone_str, region)\n",
    "        is_possible = phonenumbers.is_possible_number(parsed_phone)\n",
    "        is_valid = phonenumbers.is_valid_number(parsed_phone)\n",
    "        \n",
    "        # Perform validation check before formatting phone\n",
    "        if strictly_validate:\n",
    "            if is_possible and is_valid:\n",
    "                return phonenumbers.format_number(parsed_phone, output_format)\n",
    "            else:\n",
    "                # Return pd.na if phone is not valid\n",
    "                return pd.NA\n",
    "        else:\n",
    "            if is_possible:\n",
    "                return phonenumbers.format_number(parsed_phone, output_format)\n",
    "            else:\n",
    "                # Return pd.na if phone is not structurally possible\n",
    "                return pd.NA\n",
    "            \n",
    "    except phonenumbers.NumberParseException as e:\n",
    "        # Catch unexpected Errors during processing (e.g.. empty string, malformed phone)\n",
    "        return pd.NA\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing '{phone_str}': {e}\")\n",
    "        return pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for phone standardization\n",
    "def standardize_phone(data: pd.DataFrame,\n",
    "                      region: str = \"US\",\n",
    "                      output_format: phonenumbers.PhoneNumberFormat = phonenumbers.PhoneNumberFormat.E164,\n",
    "                      strictly_validate: bool = False,\n",
    "                      keywords: list[str] = None\n",
    "                      ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to standardize phone number columns across an entire DataFrame. \n",
    "    \n",
    "    It automatically identifies columns likely containing phone data\n",
    "    based on common naming conventions (keywords), then processes each identified\n",
    "    column to parse, validate, and format phone numbers to a consistent standard.\n",
    "    It leverages the `phonenumbers` library for robust handling of international\n",
    "    formats, invalid entries, and missing values.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The input DataFrame that needs phone number standardization.\n",
    "        keywords (list[str], optional): A list of substrings to look for in column names.\n",
    "                                        Columns whose names (case-insensitively) contain\n",
    "                                        any of these keywords will be considered for\n",
    "                                        phone number standardization.\n",
    "                                        Defaults to common phone-related terms.\n",
    "        region (str, optional): The two-letter ISO 3166-1 country code\n",
    "                                        (e.g., \"US\", \"GH\", \"GB\") to assume for\n",
    "                                        phone numbers that do not have an explicit\n",
    "                                        country code (e.g., \"5551234567\"). This is\n",
    "                                        critical for correct parsing. Defaults to \"US\".\n",
    "        output_format (phonenumbers.PhoneNumberFormat, optional): The desired\n",
    "                                                                  standard output format\n",
    "                                                                  for the phone numbers.\n",
    "                                                                  Defaults to E.164.\n",
    "                                                                  Options include:\n",
    "                                                                  - `phonenumbers.PhoneNumberFormat.E164` (e.g., \"+15551234567\")\n",
    "                                                                  - `phonenumbers.PhoneNumberFormat.INTERNATIONAL` (e.g., \"+1 555-123-4567\")\n",
    "                                                                  - `phonenumbers.PhoneNumberFormat.NATIONAL` (e.g., \"(555) 123-4567\" for US)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the identified phone number column(s)\n",
    "                      standardized. Original columns are unchanged if no phone\n",
    "                      data is found or processed.\n",
    "    \"\"\"\n",
    "    print(\"--- Initiating phone number standardization process ---\\n\")\n",
    "\n",
    "    data = data.copy()\n",
    "\n",
    "    # Defined default keywords for phone column detection if None\n",
    "    if keywords == None:\n",
    "        keywords = [\"phone\", \"number\", \"contact\", \"mobile\", \"tel\", \"cell\", \"telephone\", \"fax\"]\n",
    "\n",
    "    processed_columns: list[str] = []\n",
    "\n",
    "    # Retreive potential phone number columns\n",
    "    for column in data.columns:\n",
    "\n",
    "        if any(keyword in column.lower() for keyword in keywords):\n",
    "            print(f\"Processing potential phone column '{column}'\\n\")\n",
    "\n",
    "            # Prepare, parse, format and validate phone using the helper function\n",
    "            process_phone = (\n",
    "                data[column].astype(str)\n",
    "                            .replace(r\"^\\s*$\", \"\", regex=True)\n",
    "                            .replace(\"nan\", \"\", regex=True)\n",
    "            )\n",
    "\n",
    "            # Perform validation check before formatting phone\n",
    "            if strictly_validate:\n",
    "                data[column] = process_phone.apply(\n",
    "                    lambda x: _parse_and_format_phone(x, region, output_format, strictly_validate=True)\n",
    "                )\n",
    "                data[column] = data[column].astype(pd.StringDtype())\n",
    "                print(f\"'{column}' column processed.\")\n",
    "            else:\n",
    "                # Ignore validation check, format phone\n",
    "                data[column] = process_phone.apply(\n",
    "                    lambda x: _parse_and_format_phone(x, region, output_format, strictly_validate=False)\n",
    "                )\n",
    "                data[column] = data[column].astype(pd.StringDtype())\n",
    "                print(f\"'{column}' column processed.\")\n",
    "\n",
    "            # Report on na or invalid phone numbers\n",
    "            number_of_na = data[column].isnull().sum()\n",
    "            if number_of_na > 0:\n",
    "                print(f\"{number_of_na} phone numbers failed to parse/validate. Set to NA in '{column}' column.\\n\")\n",
    "\n",
    "            processed_columns.append(column)\n",
    "        \n",
    "    # Report on whether any column(s) were standardized\n",
    "    if len(processed_columns) == 0:\n",
    "        print(\"No columns matching phone keywords were found in the DataFrame to standardize.\")\n",
    "    else:\n",
    "        print(f\"Phone number standardization complete for the following column(s):\")\n",
    "        print(processed_columns)\n",
    "    \n",
    "    print(\"\\n--- Phone number standardization process complete ---\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d6d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type before standardizing\n",
    "df['phone_number'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bc62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initiating phone number standardization process ---\n",
      "\n",
      "Processing potential phone column 'phone_number'\n",
      "\n",
      "'phone_number' column processed.\n",
      "Phone number standardization complete for the following column(s):\n",
      "['phone_number']\n",
      "\n",
      "--- Phone number standardization process complete ---\n"
     ]
    }
   ],
   "source": [
    "df_clean = standardize_phone(df, region=\"US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaef7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     +15551234567\n",
       "1     +15559876543\n",
       "2     +15551234567\n",
       "3     +15555555555\n",
       "4     +15557890123\n",
       "5     +15551112222\n",
       "6     +15559876543\n",
       "7     +15559876543\n",
       "8     +15551237890\n",
       "9     +15554443333\n",
       "10    +15552221111\n",
       "11    +15557894561\n",
       "12    +15551112222\n",
       "13    +15553339876\n",
       "14    +15556667777\n",
       "15    +15551237890\n",
       "16    +15557894561\n",
       "17    +15559876543\n",
       "Name: phone_number, dtype: string"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type after standardizing\n",
    "df_clean['phone_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b52828",
   "metadata": {},
   "source": [
    "- clean and validate email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1917b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for email validation and cleaning\n",
    "def _clean_email(email: Union[str, float]) -> Union[str, float]:\n",
    "    \"\"\"\n",
    "    Cleans and validates a single email string.\n",
    "\n",
    "    This helper function performs the following steps:\n",
    "    1. Handles pandas NaN values, returning them directly.\n",
    "    2. Converts the input to a string and strips leading/trailing whitespace.\n",
    "    3. Validates the email against a common regular expression pattern.\n",
    "       The pattern allows alphanumeric characters, '.', '_', '%', '+', '-' before '@',\n",
    "       and alphanumeric characters, '.', '-' after '@', followed by a top-level domain\n",
    "       of at least two letters.\n",
    "    4. If the email is valid, it's converted to lowercase and returned.\n",
    "    5. If the email is not a string, or does not match the valid pattern,\n",
    "       it returns `np.nan` (Not a Number) to indicate an invalid or unfixable email.\n",
    "\n",
    "    Args:\n",
    "        email (Union[str, float]): The email string to clean. Can also be a float\n",
    "                                   if it's a NaN value from a DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Union[str, float]: The cleaned, lowercase email string if valid,\n",
    "                           otherwise `np.nan`.\n",
    "\n",
    "    Example:\n",
    "        >>> clean_email(\" test@example.com \")\n",
    "        'test@example.com'\n",
    "        >>> clean_email(\"invalid-email\")\n",
    "        nan\n",
    "        >>> clean_email(\"user@domain.co.uk\")\n",
    "        'user@domain.co.uk'\n",
    "        >>> clean_email(np.nan)\n",
    "        nan\n",
    "        >>> clean_email(123)\n",
    "        nan\n",
    "    \"\"\"\n",
    "    # Handle NaN values\n",
    "    if pd.isna(email):\n",
    "        return np.nan\n",
    "\n",
    "    # Ensure input is string\n",
    "    if not isinstance(email, str):\n",
    "        return np.nan\n",
    "    \n",
    "    # Strip leading/trailing whitespace.\n",
    "    email = email.strip()\n",
    "    \n",
    "    # Basic valid email pattern\n",
    "    email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9._]+\\.[a-zA-Z]{2,}$\"\n",
    "\n",
    "\n",
    "    # Check if email is valid then return, else return null\n",
    "    if re.match(email_pattern, email):\n",
    "        return email.lower()\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71dbd7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def clean_email(\n",
    "    data: pd.DataFrame,\n",
    "    email_keywords: list[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Identifies and cleans email columns within a pandas DataFrame.\n",
    "\n",
    "    This function iterates through the DataFrame's columns, identifies potential\n",
    "    email columns based on a list of keywords, and applies the `clean_email`\n",
    "    helper function to clean and validate the email entries in those columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input pandas DataFrame.\n",
    "        email_keywords (List[str], optional): A list of keywords (case-insensitive)\n",
    "            to identify columns likely containing email addresses. Common keywords\n",
    "            include 'email', 'mail', 'e-mail', 'contact_email', etc.\n",
    "            If None, a default list ['email', 'mail', 'e-mail', 'contact'] will be used.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the identified email columns cleaned.\n",
    "                      Original DataFrame is not modified.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the input `df` is not a pandas DataFrame.\n",
    "\n",
    "    Example:\n",
    "        >>> data = {\n",
    "        ...     'id': [1, 2, 3, 4],\n",
    "        ...     'customer_email': [' test@example.com ', 'invalid', 'user@domain.co.uk', np.nan],\n",
    "        ...     'mailing_address': ['123 Main St', '456 Oak Ave', '789 Pine Ln', '101 Elm St'],\n",
    "        ...     'email_backup': ['another@example.org', 'no_at_sign', 'user@domain', 'valid@sub.domain.com']\n",
    "        ... }\n",
    "        >>> df = pd.DataFrame(data)\n",
    "        >>> cleaned_df = clean_email_columns(df)\n",
    "        Processing column: customer_email\n",
    "        Processing column: email_backup\n",
    "        >>> print(cleaned_df[['customer_email', 'email_backup']])\n",
    "             customer_email        email_backup\n",
    "        0  test@example.com another@example.org\n",
    "        1               NaN                 NaN\n",
    "        2  user@domain.co.uk                 NaN\n",
    "        3               NaN  valid@sub.domain.com\n",
    "    \"\"\"\n",
    "    print(\"--- Initiating email cleaning process ---\\n\\n\")\n",
    "    \n",
    "    data = data.copy()\n",
    "\n",
    "    # Define default email_keywords\n",
    "    if email_keywords == None:\n",
    "        email_keywords = ['email', 'mail', 'e-mail', 'contact']\n",
    "    \n",
    "    cleaned_email_columns: list[str] = []\n",
    "\n",
    "    # Try to identify potential email columns using email_keywords\n",
    "    for column in data.columns:\n",
    "        if any(keyword in column.lower() for keyword in email_keywords):\n",
    "            print(f\"Processing column: '{column}'...\\n\")\n",
    "            cleaned_email_columns.append(column)\n",
    "            try:\n",
    "                # Apply helper function to identified columns\n",
    "                data[column] = data[column].apply(\n",
    "                    lambda x: _clean_email(x)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error cleaning column '{column}': {e}.\\n\")\n",
    "    \n",
    "    if not cleaned_email_columns:\n",
    "        print(f\"No columns indentied as email columns based on provided keywords.\\n\")\n",
    "    else:\n",
    "        print(f\"Successfully cleaned email columns:\")\n",
    "        print(cleaned_email_columns)\n",
    "    \n",
    "    print(\"\\n\\n--- Email cleaning process complete ---\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a6fb689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18 entries, 0 to 17\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               18 non-null     int64  \n",
      " 1   name             17 non-null     object \n",
      " 2   age              17 non-null     float64\n",
      " 3   gender           18 non-null     object \n",
      " 4   email            18 non-null     object \n",
      " 5   income           17 non-null     float64\n",
      " 6   job_title        18 non-null     object \n",
      " 7   department       18 non-null     object \n",
      " 8   start_date       18 non-null     object \n",
      " 9   education        18 non-null     object \n",
      " 10  customer_rating  16 non-null     float64\n",
      " 11  comments         17 non-null     object \n",
      " 12  phone_number     18 non-null     object \n",
      " 13  country          18 non-null     object \n",
      " 14  purchase_amount  18 non-null     object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hr_data_1.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "26d1066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         john.smith@email.com\n",
       "1           jane.doe@email.com\n",
       "2                  bob.j@email\n",
       "3        mike.wilson@email.com\n",
       "4            sarah.w@email.com\n",
       "5               alex@email.com\n",
       "6              emilyincomplete\n",
       "7     different.jane@email.com\n",
       "8       chris.martin@email.com\n",
       "9             lisa.j@email.com\n",
       "10           david.t@email.com\n",
       "11              jennifer@email\n",
       "12            mscott@email.com\n",
       "13       amanda.king@email.com\n",
       "14         ryan.chen@email.com\n",
       "15      chris.martin@email.com\n",
       "16              jennifer@email\n",
       "17            emily@incomplete\n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type before standardizing\n",
    "df['email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd093a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initiating email cleaning process ---\n",
      "\n",
      "\n",
      "Processing column: 'email'...\n",
      "\n",
      "Successfully cleaned email columns:\n",
      "['email']\n",
      "\n",
      "\n",
      "--- Email cleaning process complete ---\n"
     ]
    }
   ],
   "source": [
    "df = clean_email(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58aeba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         john.smith@email.com\n",
       "1           jane.doe@email.com\n",
       "2                          NaN\n",
       "3        mike.wilson@email.com\n",
       "4            sarah.w@email.com\n",
       "5               alex@email.com\n",
       "6                          NaN\n",
       "7     different.jane@email.com\n",
       "8       chris.martin@email.com\n",
       "9             lisa.j@email.com\n",
       "10           david.t@email.com\n",
       "11                         NaN\n",
       "12            mscott@email.com\n",
       "13       amanda.king@email.com\n",
       "14         ryan.chen@email.com\n",
       "15      chris.martin@email.com\n",
       "16                         NaN\n",
       "17                         NaN\n",
       "Name: email, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type after standardizing\n",
    "df['email']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b0b77",
   "metadata": {},
   "source": [
    "- handle basic text inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] = df['name'].str.title()     #convert names title case\n",
    "df['country'] = df['country'].str.upper()   #convert country names to uppercase\n",
    "df['job_title'] = df['job_title'].str.lower()   #convert country names to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b975c99",
   "metadata": {},
   "source": [
    "- standardize text data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27b046e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for mapping text inconsistencies to a valid text value based on keywords (logic-based standardization)\n",
    "def standardize_by_keyword(string: str,\n",
    "                            keyword_map: dict[str, list[str]],\n",
    "                            default: Optional[str] = \"Other\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Standardizes a text string by searching for keywords.\n",
    "\n",
    "    This function checks if any of the keywords from the provided map are\n",
    "    present in the input text. It's useful for categorizing free-form text\n",
    "    fields like job titles or education descriptions.\n",
    "\n",
    "    Args:\n",
    "        string (str): The input string to standardize. Can be any type, but will\n",
    "                    be converted to a string. Handles NaN values.\n",
    "        keyword_map (Dict[str, List[str]]): A dictionary where keys are the\n",
    "                                           target standardized values and\n",
    "                                           values are lists of keywords to\n",
    "                                           search for.\n",
    "        default (Optional[str], optional): The value to return if no keywords\n",
    "                                           are found. Defaults to \"Other\".\n",
    "                                           Use None if you want NaN output.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The standardized text, the default value, or np.nan\n",
    "                       if the input was a NaN value.\n",
    "    \"\"\"\n",
    "    # Handle NaN values\n",
    "    if pd.isna(string):\n",
    "        return np.nan\n",
    "    \n",
    "    # Consistent matching of string\n",
    "    processed_string = (string.lower()\n",
    "                              .strip()\n",
    "                              .replace(\" \", \"\")\n",
    "                              )\n",
    "\n",
    "    # Iterate through mapping rules\n",
    "    for standard_value, keywords in keyword_map.items():\n",
    "        # Check if any keyword for current category is in the processed text\n",
    "        if any(keyword in processed_string for keyword in keywords):\n",
    "            return standard_value\n",
    "    \n",
    "    # Return default if no matches found\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Helper function to create a dictionary of mapped keywords to standardization values\n",
    "\n",
    "def _create_map(standard_categories: list[str],\n",
    "                category_keywords: list[list[str]]) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Generates a lookup map for standardizing values in a column\n",
    "    if the value contains specific keywords.\n",
    "\n",
    "    This function generates an output which in turn is used during the \n",
    "    standardization of columns by keywords.\n",
    "\n",
    "    Args:\n",
    "        standard_categories (list[str]): This is the list of values that will be used\n",
    "                                              for standardization.\n",
    "        category_keywords (list[list[str]]): A list where each inner list contains\n",
    "                                                keywords/variations that map to the\n",
    "                                                corresponding standard category in\n",
    "                                                `standard_categories`. The order\n",
    "                                                of inner lists must match the order\n",
    "                                                of `standard_categories`. \n",
    "                                                 \n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary where keys are standard categories,\n",
    "                        and values are a list of keywords that may be found in\n",
    "                        the category.\n",
    "    \"\"\"\n",
    "    map = {}\n",
    "\n",
    "    for category in standard_categories:\n",
    "        for keyword_list in category_keywords:\n",
    "            if any(keyword in category.lower() for keyword in keyword_list):\n",
    "                map[category] = keyword_list\n",
    "    \n",
    "    return map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114a6726",
   "metadata": {},
   "source": [
    "**a. test on 'education'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66515c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Bachelor's\", 'Masters', 'bachelor', 'PHD', 'Masters Degree',\n",
       "       'Bachelors', \"bachelor's degree\", 'MBA', 'masters degree',\n",
       "       'Ba chelor', 'PhD', 'MSc'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current values of 'education'\n",
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca68a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments for standardizing 'education'\n",
    "degree_list = [\"Bachelor's Degree\", \"Master's Degree\", \"Doctorate\"]\n",
    "degree_keyword_lists = [[\"phd\", \"doctor\"], [\"master\", \"msc\"], [\"bachelor\", \"bsc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6034419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Bachelor's Degree\": ['bachelor', 'bsc'],\n",
       " \"Master's Degree\": ['master', 'msc'],\n",
       " 'Doctorate': ['phd', 'doctor']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_map = _create_map(standard_categories=degree_list,\n",
    "                            category_keywords=degree_keyword_lists)\n",
    "education_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c5e9b2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Bachelor's Degree\n",
       "1       Master's Degree\n",
       "2     Bachelor's Degree\n",
       "3             Doctorate\n",
       "4       Master's Degree\n",
       "5     Bachelor's Degree\n",
       "6             Doctorate\n",
       "7       Master's Degree\n",
       "8     Bachelor's Degree\n",
       "9                   MBA\n",
       "10      Master's Degree\n",
       "11    Bachelor's Degree\n",
       "12    Bachelor's Degree\n",
       "13            Doctorate\n",
       "14      Master's Degree\n",
       "15    Bachelor's Degree\n",
       "16    Bachelor's Degree\n",
       "17            Doctorate\n",
       "Name: education, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to 'education'\n",
    "df['education'].apply(\n",
    "    lambda x: standardize_by_keyword(\n",
    "        string=x,\n",
    "        keyword_map=education_map,\n",
    "        default='MBA'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253fed2",
   "metadata": {},
   "source": [
    "**b. test on 'job_title'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5ec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sr. Developer', 'Senior Developer', 'Data Analyst',\n",
       "       'Project Manager', 'UX Designer', 'senior developer',\n",
       "       'Data Scientist', 'Marketing Specialist', 'Product Manager',\n",
       "       'Director', 'HR Specialist', 'Regional Manager', 'Lead Engineer',\n",
       "       'BI Analyst'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current values of 'job_title'\n",
    "df['job_title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "48a2790b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments for standardizing 'job_title'\n",
    "job_list = [\"Developer\", \"Designer\", \"Manager\", \"Data\", \"Specialist\"]\n",
    "job_keyword_lists = [[\"developer\"], [\"designer\"], [\"manager\"], [\"specialist\"], [\"data\", \"bi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a963719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Developer': ['developer'],\n",
       " 'Designer': ['designer'],\n",
       " 'Manager': ['manager'],\n",
       " 'Data': ['data', 'bi'],\n",
       " 'Specialist': ['specialist']}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title_map = _create_map(standard_categories=job_list,\n",
    "                            category_keywords=job_keyword_lists)\n",
    "job_title_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "038edc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Developer\n",
       "1      Developer\n",
       "2           Data\n",
       "3        Manager\n",
       "4       Designer\n",
       "5      Developer\n",
       "6           Data\n",
       "7      Developer\n",
       "8     Specialist\n",
       "9        Manager\n",
       "10     Developer\n",
       "11    Specialist\n",
       "12       Manager\n",
       "13     Developer\n",
       "14          Data\n",
       "15    Specialist\n",
       "16    Specialist\n",
       "17          Data\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to 'job_title'\n",
    "df['job_title'].apply(\n",
    "    lambda x: standardize_by_keyword(\n",
    "        string=x,\n",
    "        keyword_map=job_title_map,\n",
    "        default='Developer'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8552e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for exact-match for mapping inconsistencies to a valid text value (rule-based standardization)\n",
    "def standardize_by_lookup(string: str,\n",
    "                           lookup_map: dict[str, str],\n",
    "                           default: Optional[str] = \"Other\") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Standardizes a text string using an exact-match lookup dictionary.\n",
    "\n",
    "    This function cleans text by mapping discrete, inconsistent values to a\n",
    "    single, standardized value. It's ideal for columns like 'country' or\n",
    "    'gender'. The keys in the lookup_map should be lowercase.\n",
    "\n",
    "    Args:\n",
    "        text (Any): The input text to standardize. Can be any type, but will\n",
    "                    be converted to a string. Handles NaN values.\n",
    "        lookup_map (Dict[str, str]): A dictionary where keys are the raw,\n",
    "                                     lowercase text values and values are the\n",
    "                                     target standardized values.\n",
    "        default (Optional[str], optional): The value to return if the text is\n",
    "                                           not found in the lookup_map keys.\n",
    "                                           Defaults to \"Other\".\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The standardized text, the default value, or np.nan\n",
    "                       if the input was a NaN value.\n",
    "    \"\"\"\n",
    "    # Handle missing values\n",
    "    if pd.isna(string):\n",
    "        return np.nan\n",
    "    \n",
    "    # Pre-process string\n",
    "    processed_string = str(string).strip()\n",
    "\n",
    "    # Standardize string by lookup if found, else return the default\n",
    "    if processed_string.capitalize() or processed_string.upper() or processed_string.lower():\n",
    "        return lookup_map.get(processed_string, default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b94ef",
   "metadata": {},
   "source": [
    "**a. test on 'country'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a25951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               USA\n",
       "1     united states\n",
       "2                US\n",
       "3     United States\n",
       "4               usa\n",
       "5     United States\n",
       "6                US\n",
       "7               USA\n",
       "8            U.S.A.\n",
       "9     United States\n",
       "10               us\n",
       "11              USA\n",
       "12    United states\n",
       "13              usa\n",
       "14    United States\n",
       "15           U.S.A.\n",
       "16              USA\n",
       "17               US\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current values of country\n",
    "df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c8877ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific helper function to return dictionary of unique country values and values for standardization\n",
    "def _create_country_map() -> dict[str, str]:\n",
    "        # Get unique values in 'country' to create a dictionary\n",
    "        country_map = {}\n",
    "\n",
    "        for unique_value in list(df['country'].unique()):\n",
    "                country_map[unique_value] = \"USA\"\n",
    "        \n",
    "        return country_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7504f000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'USA': 'USA',\n",
       " 'united states': 'USA',\n",
       " 'US': 'USA',\n",
       " 'United States': 'USA',\n",
       " 'usa': 'USA',\n",
       " 'U.S.A.': 'USA',\n",
       " 'us': 'USA',\n",
       " 'United states': 'USA'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_country_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28fb1f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     USA\n",
       "1     USA\n",
       "2     USA\n",
       "3     USA\n",
       "4     USA\n",
       "5     USA\n",
       "6     USA\n",
       "7     USA\n",
       "8     USA\n",
       "9     USA\n",
       "10    USA\n",
       "11    USA\n",
       "12    USA\n",
       "13    USA\n",
       "14    USA\n",
       "15    USA\n",
       "16    USA\n",
       "17    USA\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to 'country'\n",
    "df['country'].apply(\n",
    "    lambda x: standardize_by_lookup(\n",
    "        string=x,\n",
    "        lookup_map=_create_country_map()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842dee02",
   "metadata": {},
   "source": [
    "**b. test on 'gender'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          M\n",
       "1          F\n",
       "2       Male\n",
       "3          M\n",
       "4     female\n",
       "5          M\n",
       "6          F\n",
       "7     Female\n",
       "8          M\n",
       "9          F\n",
       "10      Male\n",
       "11         F\n",
       "12         M\n",
       "13         f\n",
       "14         M\n",
       "15         M\n",
       "16         F\n",
       "17         F\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current values of 'gender'\n",
    "df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ac11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific helper function to return dictionary of unique gender values and values for standardization\n",
    "def _create_gender_map(series: pd.Series) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates a lookup map for standardizing gender values.\n",
    "\n",
    "    This function processes unique values in the input Pandas Series and\n",
    "    maps them to \"male\", \"female\", or \"other\" using predefined regex patterns.\n",
    "    The keys in the returned map are lowercased and stripped versions of the\n",
    "    original unique values from the series.\n",
    "\n",
    "    Args:\n",
    "        gender_series (pd.Series): The Pandas Series (e.g., df['gender'])\n",
    "                                   containing raw gender values.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary where keys are processed unique gender strings,\n",
    "                        and values are their standardized \"male\", \"female\", or \"other\" category.\n",
    "    \"\"\"\n",
    "    gender_map = {}\n",
    "    unique_gender_values = series.unique()\n",
    "\n",
    "    for gender in unique_gender_values:\n",
    "        # Skip NaN values\n",
    "        if pd.isna(gender):\n",
    "            continue\n",
    "\n",
    "        # Process the string for consistency in mapping keys\n",
    "        processed_gender = str(gender).strip()\n",
    "\n",
    "        # Apply the 'gender' regex logic\n",
    "        if re.match(r\"^[Mm][a-zA-Z]*$\", processed_gender):\n",
    "            gender_map[processed_gender] = \"male\"\n",
    "        elif re.match(r\"^[Ff][a-zA-Z]*$\", processed_gender):\n",
    "            gender_map[processed_gender] = \"female\"\n",
    "\n",
    "    return gender_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d406f274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'M': 'male',\n",
       " 'F': 'female',\n",
       " 'Male': 'male',\n",
       " 'female': 'female',\n",
       " 'Female': 'female',\n",
       " 'f': 'female'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_gender_map(df['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2082b245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       male\n",
       "1     female\n",
       "2       male\n",
       "3       male\n",
       "4     female\n",
       "5       male\n",
       "6     female\n",
       "7     female\n",
       "8       male\n",
       "9     female\n",
       "10      male\n",
       "11    female\n",
       "12      male\n",
       "13    female\n",
       "14      male\n",
       "15      male\n",
       "16    female\n",
       "17    female\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to 'gender'\n",
    "df['gender'].apply(\n",
    "    lambda x: standardize_by_lookup(\n",
    "        string=x,\n",
    "        lookup_map=_create_gender_map(df['gender'])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4dc2da",
   "metadata": {},
   "source": [
    "**c. test on 'department'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abe8a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IT', 'Engineering', 'Analytics', 'Design', 'Marketing', 'Product',\n",
       "       'Executive', 'Human Resources', 'Management'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current values of 'department'\n",
    "df['department'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07760b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific helper function to return dictionary of unique department values and values for standardization\n",
    "def _create_department_map() -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Generates a lookup map for standardizing specific department names\n",
    "    into predefined broader categories (Technology, Creative, Business,\n",
    "    Management, Operations).\n",
    "\n",
    "    This function maps each department to a standardization value which\n",
    "    are hardcoded, and returns a dictionary with the departments as keys,\n",
    "    and the standardization values as values of the dictionary.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary where keys are processed unique department strings,\n",
    "                        and values are their standardized broad categories.\n",
    "    \"\"\"\n",
    "    # Initialize a map for department values\n",
    "    department_map = {}\n",
    "\n",
    "    # Hardcoded lists of departments for standardization\n",
    "    technology_list = ['IT', 'Engineering', 'Analytics']\n",
    "    creative_list = ['Design']\n",
    "    business_list = ['Marketing', 'Product']\n",
    "    management_list = ['Executive', 'Management']\n",
    "    operations_list = ['Human Resources']\n",
    "\n",
    "    # Iterate through departments\n",
    "    for department in df['department'].unique():\n",
    "        if department in technology_list:\n",
    "            department_map[department] = \"Technology\"\n",
    "        elif department in creative_list:\n",
    "            department_map[department] = \"Creative\"\n",
    "        elif department in business_list:\n",
    "            department_map[department] = \"Business\"\n",
    "        elif department in management_list:\n",
    "            department_map[department] = \"Management\"\n",
    "        elif department in operations_list:\n",
    "            department_map[department] = \"Operations\"\n",
    "    \n",
    "    return department_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01d4372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT': 'Technology',\n",
       " 'Engineering': 'Technology',\n",
       " 'Analytics': 'Technology',\n",
       " 'Design': 'Creative',\n",
       " 'Marketing': 'Business',\n",
       " 'Product': 'Business',\n",
       " 'Executive': 'Management',\n",
       " 'Human Resources': 'Operations',\n",
       " 'Management': 'Management'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_create_department_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccef9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Technology\n",
       "1     Technology\n",
       "2     Technology\n",
       "3     Technology\n",
       "4       Creative\n",
       "5     Technology\n",
       "6     Technology\n",
       "7     Technology\n",
       "8       Business\n",
       "9       Business\n",
       "10    Management\n",
       "11    Operations\n",
       "12    Management\n",
       "13    Technology\n",
       "14    Technology\n",
       "15      Business\n",
       "16    Operations\n",
       "17    Technology\n",
       "Name: department, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to 'department'\n",
    "df['department'].apply(\n",
    "    lambda x: standardize_by_lookup(\n",
    "        string=x,\n",
    "        lookup_map=_create_department_map(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb929e3",
   "metadata": {},
   "source": [
    "### 5. Handle Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68189dd8",
   "metadata": {},
   "source": [
    "Perform the following:\n",
    "- Detect Outliers if present\n",
    "- Visualize Outliers if present\n",
    "- take care of outliers by Winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d96a1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers Helper function\n",
    "def _contains_outliers(data: pd.Series) -> bool:\n",
    "    \"\"\"\n",
    "    Identifies and counts outliers in a numeric pandas Series using the\n",
    "    Interquartile Range (IQR) method.\n",
    "\n",
    "    Outliers are defined as values that fall below `Q1 - 1.5 * IQR` or\n",
    "    above `Q3 + 1.5 * IQR`, where Q1 is the first quartile (25th percentile),\n",
    "    Q3 is the third quartile (75th percentile), and IQR is the interquartile\n",
    "    range (Q3 - Q1).\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): A pandas Series (numeric column) to check for outliers.\n",
    "                          Non-numeric data will raise a TypeError.\n",
    "\n",
    "    Returns:\n",
    "        int: The total count of identified outliers in the Series.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the input `data` Series is not of a numeric data type.\n",
    "        ValueError: If the Series is empty or contains too few non-NaN values\n",
    "                    to calculate quartiles.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> # Example with outliers\n",
    "        >>> s1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 100])\n",
    "        >>> num_outliers_s1 = get_outliers(s1)\n",
    "        >>> print(f\"Number of outliers in s1: {num_outliers_s1}\")\n",
    "        Number of outliers in s1: 1\n",
    "\n",
    "        >>> # Example with no outliers\n",
    "        >>> s2 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "        >>> num_outliers_s2 = get_outliers(s2)\n",
    "        >>> print(f\"Number of outliers in s2: {num_outliers_s2}\")\n",
    "        Number of outliers in s2: 0\n",
    "\n",
    "        >>> # Example with NaN values\n",
    "        >>> s3 = pd.Series([1, 2, 3, np.nan, 4, 5, 6, 7, 8, 100])\n",
    "        >>> num_outliers_s3 = get_outliers(s3)\n",
    "        >>> print(f\"Number of outliers in s3: {num_outliers_s3}\")\n",
    "        Number of outliers in s3: 1\n",
    "\n",
    "        >>> # Example with non-numeric data (will raise TypeError)\n",
    "        >>> try:\n",
    "        ...     get_outliers(pd.Series(['a', 'b', 'c']))\n",
    "        ... except TypeError as e:\n",
    "        ...     print(e)\n",
    "        Input Series must be numeric.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate data type \n",
    "    if not is_numeric_dtype(data):\n",
    "        raise TypeError(\"Input Series must be numeric\")\n",
    "    \n",
    "    # Drop nulls for quartile calculation\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Ensure there is enough values for quartile calculation\n",
    "    if len(data) < 2:\n",
    "        return 0    # No outliers if data is insufficient\n",
    "\n",
    "    try:\n",
    "        # Calculate first and third quartiles\n",
    "        first_quartile = data.quantile(.25)\n",
    "        third_quartile = data.quantile(.75)\n",
    "\n",
    "        # Calculate inter quartile range\n",
    "        iqr = third_quartile - first_quartile\n",
    "\n",
    "        lower_bound = first_quartile - (1.5 * iqr)\n",
    "        upper_bound = third_quartile + (1.5 * iqr)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Could not calculate quartiles for the Series. Error: {e}\")\n",
    "    \n",
    "    # Create boolean series to indicate outlier values\n",
    "    outlier_mask = ((data < lower_bound) | (data > upper_bound))\n",
    "\n",
    "    return outlier_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd59e395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'income' contains 3 number of outliers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_contains_outliers(df['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71696275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers function\n",
    "def visualize_outliers_boxplot(data: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Create a boxplot and strip plot with individual data points\n",
    "    to highlight outliers and their positions on the boxplot in a numeric pandas Series using Seaborn.\n",
    "\n",
    "    The plot is only generated if the `_contains_outliers` helper function\n",
    "    indicates that outliers are present in the data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): The numeric pandas Series to visualize.\n",
    "       \n",
    "    Returns:\n",
    "        None: This function displays the plot directly.\n",
    "    \"\"\"\n",
    "    # Validate data input\n",
    "    if not is_numeric_dtype(data):\n",
    "        raise TypeError(\"Input Series must be numeric\")\n",
    "    \n",
    "    # Validate outlier presence before plotting \n",
    "    if not _contains_outliers(data):\n",
    "        print(f\"No outliers detected in '{data.name if data.name else 'this'}' column.\")\n",
    "    else:\n",
    "        print(f\"'{data.name if data.name else 'This'}' column has {_contains_outliers(data)} outliers visualized below: \\n\")\n",
    "        # Get column name else assign one\n",
    "        column_name = data.name if data.name is not None else \"Value\"\n",
    "\n",
    "        # Plot outliers (Boxplot)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        sns.boxplot(y=data, color='skyblue')\n",
    "        sns.stripplot(y=data, color='darkred')\n",
    "\n",
    "        plt.title(f\"Distribution of {column_name.title()} with Outliers Detected\")\n",
    "        plt.ylabel(column_name)\n",
    "\n",
    "        # Remove x-axis tick and label\n",
    "        plt.xticks([])\n",
    "        plt.tick_params(axis='x', length=0)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6613a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'income' contains 3 number of outliers\n",
      "'income' column outliers are visualized below: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_outliers_boxplot(df['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f96563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform winsorization (cap outliers)\n",
    "def winsorize_series(data: pd.Series,\n",
    "              lower_percentile: float =.01,\n",
    "              upper_percentile: float =.99) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Performs winsorization on a numeric pandas Series by capping values\n",
    "    at specified lower and upper percentiles.\n",
    "\n",
    "    This function only executes the winsorization if the input Series\n",
    "    is identified as containing outliers by the `_contains_outliers` helper.\n",
    "    If no outliers are detected, the original Series is returned unchanged.\n",
    "\n",
    "    Winsorization replaces values outside the specified percentile range with\n",
    "    the values at those percentiles. For example, if lower_percentile is 0.01\n",
    "    and upper_percentile is 0.99, any value below the 1st percentile will be\n",
    "    set to the value at the 1st percentile, and any value above the 99th\n",
    "    percentile will be set to the value at the 99th percentile.\n",
    "\n",
    "    Args:\n",
    "        data (pd.Series): The numeric pandas Series on which to perform winsorization.\n",
    "                          Non-numeric data will raise a TypeError.\n",
    "        lower_percentile (float, optional): The lower percentile (0.0 to 1.0)\n",
    "                                            to use for capping. Defaults to 0.01 (1st percentile).\n",
    "        upper_percentile (float, optional): The upper percentile (0.0 to 1.0)\n",
    "                                            to use for capping. Defaults to 0.99 (99th percentile).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A new pandas Series with outliers capped at the specified percentiles.\n",
    "                   Returns the original Series unchanged if no outliers are detected\n",
    "                   or if the input Series is not numeric or has insufficient data.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the input `data` Series is not of a numeric data type.\n",
    "        ValueError: If `lower_percentile` or `upper_percentile` are invalid\n",
    "                    (e.g., outside 0-1 range, or lower > upper).\n",
    "        ValueError: If the Series contains too few non-NaN values to calculate quantiles.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> # Example with outliers\n",
    "        >>> s_outliers = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 100])\n",
    "        >>> print(\"Original Series with outliers:\")\n",
    "        >>> print(s_outliers)\n",
    "        Original Series with outliers:\n",
    "        0      1\n",
    "        1      2\n",
    "        2      3\n",
    "        3      4\n",
    "        4      5\n",
    "        5      6\n",
    "        6      7\n",
    "        7      8\n",
    "        8      9\n",
    "        9    100\n",
    "        dtype: int64\n",
    "        >>> winsorized_s = winsorize(s_outliers, lower_percentile=0.05, upper_percentile=0.95)\n",
    "        >>> print(\"\\nWinsorized Series:\")\n",
    "        >>> print(winsorized_s)\n",
    "        Winsorized Series:\n",
    "        0     1.4\n",
    "        1     2.0\n",
    "        2     3.0\n",
    "        3     4.0\n",
    "        4     5.0\n",
    "        5     6.0\n",
    "        6     7.0\n",
    "        7     8.0\n",
    "        8     8.6\n",
    "        9     8.6\n",
    "        dtype: float64\n",
    "\n",
    "        >>> # Example with no outliers (should return original series)\n",
    "        >>> s_no_outliers = pd.Series([10, 20, 30, 40, 50])\n",
    "        >>> print(\"\\nOriginal Series with no outliers:\")\n",
    "        >>> print(s_no_outliers)\n",
    "        Original Series with no outliers:\n",
    "        0    10\n",
    "        1    20\n",
    "        2    30\n",
    "        3    40\n",
    "        4    50\n",
    "        dtype: int64\n",
    "        >>> winsorized_no_outliers_s = winsorize(s_no_outliers)\n",
    "        >>> print(\"\\nWinsorized Series (no change expected):\")\n",
    "        >>> print(winsorized_no_outliers_s)\n",
    "        Winsorized Series (no change expected):\n",
    "        0    10\n",
    "        1    20\n",
    "        2    30\n",
    "        3    40\n",
    "        4    50\n",
    "        dtype: int64\n",
    "\n",
    "        >>> # Example with non-numeric data (should raise TypeError)\n",
    "        >>> try:\n",
    "        ...     winsorize(pd.Series(['a', 'b', 'c']))\n",
    "        ... except TypeError as e:\n",
    "        ...     print(f\"\\nCaught expected error: {e}\")\n",
    "        Caught expected error: Input Series must be numeric.\n",
    "    \"\"\"\n",
    "    print(\"--- Series winsorization process initiated ---\\n\")\n",
    "\n",
    "    # Validate input data\n",
    "    if not is_numeric_dtype(data):\n",
    "        raise TypeError(\"Input Series must be numeric.\")\n",
    "    \n",
    "    # Validate presence of outliers\n",
    "    if not _contains_outliers(data):\n",
    "        print(f\"The data does not contain outliers. Exiting winsorization process...\")\n",
    "    \n",
    "    # Validate Percentile values\n",
    "    if not ((0 <= lower_percentile < 1) and (0 < upper_percentile <= 1) and (lower_percentile <= upper_percentile)):\n",
    "        raise ValueError(\"Invalid percentile values: upper_percentile must be greater than lower_percentile.\")\n",
    "\n",
    "    # Make a copy of data without null values\n",
    "    data = (data.dropna()\n",
    "                .copy())\n",
    "\n",
    "    # Ensure there is enough non-NaN values for quantiles calculation\n",
    "    if len(data) < 2:\n",
    "        raise ValueError(\"Insufficient non-NaN data to calculate percentiles for winsorization.\")\n",
    "    \n",
    "    try:\n",
    "        # Define limits for capping values based on percentile and winsorize\n",
    "        lower_limit = data.quantile(lower_percentile)\n",
    "        upper_limit = data.quantile(upper_percentile)\n",
    "        winsorized_data = data.clip(lower=lower_limit, upper=upper_limit)\n",
    "        print(f\"Winsorization of '{data.name if data.name else 'this column'}' successful.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Could not calculate percentile limits for winsorization. Error: {e}\")\n",
    "    \n",
    "    print(\"\\n--- Series winsorization process complete ---\")\n",
    "    return winsorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e89a5351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Series winsorization process initiated ---\n",
      "\n",
      "Winsorization of 'income successful.\n",
      "\n",
      "--- Series winsorization process complete ---\n"
     ]
    }
   ],
   "source": [
    "df['income_capped'] = winsorize_series(df['income'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
