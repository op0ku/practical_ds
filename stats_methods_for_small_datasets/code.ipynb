{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Innovative Statistical Methods for Small Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 1. Bootstrapping\n",
    "\n",
    "Bootstrapping means sampling with replacement. That is, the samples in the replacement process can be selected more than once. This is a useful technique when one is dealing with a small dataset to conduct parametric statistical methods such as confidence interval estimation and hypothesis testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how to perform bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the data\n",
    "data = np.array([2.3, 1.9, 2.7, 2.8, 3.1])\n",
    "\n",
    "#define the number of bootstrap samples\n",
    "n_samples = 1000\n",
    "\n",
    "#define statistic function to use\n",
    "statistic = np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.1, 2.8, 2.3, 3.1, 2.3],\n",
       "       [3.1, 1.9, 1.9, 1.9, 2.7],\n",
       "       [1.9, 2.7, 2.3, 3.1, 1.9],\n",
       "       ...,\n",
       "       [2.8, 1.9, 2.8, 3.1, 2.7],\n",
       "       [2.3, 1.9, 3.1, 2.8, 2.3],\n",
       "       [3.1, 3.1, 2.7, 2.8, 1.9]], shape=(1000, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate bootstrap samples\n",
    "bootstrap_samples = np.random.choice(\n",
    "       data,\n",
    "       size=(n_samples, len(data)),\n",
    "       replace=True\n",
    "    )\n",
    "\n",
    "bootstrap_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the statistic for each bootstrap sample\n",
    "bootstrap_statistics = np.apply_along_axis(\n",
    "    statistic,\n",
    "    axis=1,\n",
    "    arr=bootstrap_samples\n",
    "    )\n",
    "\n",
    "bootstrap_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [2.22 2.9 ]\n"
     ]
    }
   ],
   "source": [
    "#find  2.5th and 97.5th percentiles of the bootstrap statistics\n",
    "confidence_interval = np.percentile(bootstrap_statistics, [2.5, 97.5])\n",
    "\n",
    "#output the confidence interval\n",
    "print(f\"95% Confidence Interval: {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above can be written as a function to make it reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function out of the bootstrap code\n",
    "def bootstrap(data, n_samples, statistic):\n",
    "    bootstrap_samples = np.random.choice(\n",
    "        data,\n",
    "        size=(n_samples, len(data)),\n",
    "        replace=True\n",
    "    )\n",
    "    bootstrap_statistics = np.apply_along_axis(\n",
    "        statistic,\n",
    "        axis=1,\n",
    "        arr=bootstrap_samples\n",
    "    )\n",
    "    confidence_interval = np.percentile(bootstrap_statistics, [2.5, 97.5])\n",
    "    print(f\"95% Confidence Interval: {confidence_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: [2.2185 2.9   ]\n"
     ]
    }
   ],
   "source": [
    "#run the function\n",
    "bootstrap(data, n_samples, statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Permutation Tests\n",
    "\n",
    "Suitable for small datasets, it is a non-parametric test that is used to test the null hypothesis that two populations are the same.  \n",
    "The test works by comparing the observed difference in means between the two populations to the distribution of differences in means that would be expected if the null hypothesis were true.  \n",
    "The p-value is then calculated as the proportion of differences in means that are greater than or equal to the observed difference in means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below shows how to perform permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the datasets\n",
    "data1 = np.array([2.3, 1.9, 2.7])\n",
    "data2 = np.array([2.8, 3.1, 3.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return the observed difference in means\n",
    "observed_difference = np.mean(data1) - np.mean(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine both datasets\n",
    "combined_data = np.concatenate([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for the permutation test\n",
    "n_permutations = 10_000\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run permutation test\n",
    "for _ in range(n_permutations):\n",
    "    #shuffle combined data\n",
    "    np.random.shuffle(combined_data)\n",
    "    #split data into 2 groups\n",
    "    split_data1 = combined_data[:len(data1)]\n",
    "    split_data2 = combined_data[len(data1):]\n",
    "    #find permuted difference in means\n",
    "    permuted_difference = np.mean(split_data1) - np.mean(split_data2)\n",
    "\n",
    "    #check if difference is as extreme as the observed difference\n",
    "    if abs(permuted_difference) >= abs(observed_difference):\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Difference: -0.8000000000000003\n",
      "P-value: 0.0468\n"
     ]
    }
   ],
   "source": [
    "# find p-value\n",
    "p_value = count / n_permutations\n",
    "\n",
    "#output result\n",
    "print(f\"Observed Difference: {observed_difference}\\nP-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function version for performing permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function out of the permutation test code\n",
    "def permutation_test(data1, data2, n_permutations=10_000):\n",
    "    observed_difference = np.mean(data1) - np.mean(data2)\n",
    "    combined_data = np.concatenate([data1, data2])\n",
    "    count = 0\n",
    "\n",
    "    for _ in range(n_permutations):\n",
    "        np.random.shuffle(combined_data)\n",
    "        permuted_difference = np.mean(combined_data[:len(data1)]) - np.mean(combined_data[len(data1):])\n",
    "        if abs(permuted_difference) >= abs(observed_difference):\n",
    "            count += 1\n",
    "    \n",
    "    p_value = count / n_permutations\n",
    "    return observed_difference, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Difference: -0.8000000000000003\n",
      "P-value: 0.0431\n"
     ]
    }
   ],
   "source": [
    "#run function\n",
    "observed_diff, p_value = permutation_test(data1, data2)\n",
    "\n",
    "print(f\"Observed Difference: {observed_diff}\\nP-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Jackknife Resampling\n",
    "\n",
    "Another non-parametric technique for estimating bias and variance from a small dataset.  \n",
    "It works by removing one data observation at a time from the data set, and recalculating the statistics each time with the remaining data.  \n",
    "The process is repeated for all the data, resulting in estimates for the overall statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for performing jackknife resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data and statistic function\n",
    "data = np.array([2.3, 1.9, 2.7, 2.8, 3.1])\n",
    "statistic = np.mean\n",
    "\n",
    "n = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute jackknife samples\n",
    "jackknife_samples = []\n",
    "\n",
    "for i in range(n):\n",
    "    #remove a data point at every iteration and find statistic for the remaining data\n",
    "    reduced_sample = np.delete(data, i)\n",
    "    jackknife_samples.append(statistic(reduced_sample))\n",
    "\n",
    "jackknife_samples = np.array(jackknife_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the jackknife mean\n",
    "jackknife_mean = np.mean(jackknife_samples)\n",
    "\n",
    "#find jackknife variance\n",
    "jackknife_variance = (n - 1) * np.mean((jackknife_samples - jackknife_mean) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife Mean: 2.56\n",
      "Jackknife Variance: 0.04360000000000007\n"
     ]
    }
   ],
   "source": [
    "# Output the jackknife mean and variance\n",
    "print(\"Jackknife Mean:\", jackknife_mean)\n",
    "print(\"Jackknife Variance:\", jackknife_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function for performing jackknife resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife(data, statistic=np.mean):\n",
    "    n = len(data)\n",
    "    jackknife_samples = np.array([statistic(np.delete(data, i)) for i in range(n)])\n",
    "    jackknife_mean = np.mean(jackknife_samples)\n",
    "    jackknife_variance = (n - 1) * np.mean((jackknife_samples - jackknife_mean) ** 2)\n",
    "    return jackknife_mean, jackknife_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, variance = jackknife(data)\n",
    "print(f\"Jackknife Mean: {mean}, Variance: {variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sign Test\n",
    "\n",
    "A non-parametric test used to evaluate the significanct difference between  the sample median and the hypothesized median.  \n",
    "It is used for small dataset and does not rely on any assumptions, unlike parametric tests   \n",
    "It is performed by counting the number of data points above or below the hypothesized median, then taking the smaller count to evalute it as the test statistic.  \n",
    "The significance is calculated by comparing the test statistics with the critical values from the binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = [12, 15, 14, 16, 13, 10]\n",
    "hypothesized_median = 14\n",
    "\n",
    "above_hypothesized = sum(value > hypothesized_median for value in data)\n",
    "below_hypothesized = sum(value < hypothesized_median for value in data)\n",
    "n = above_hypothesized + below_hypothesized\n",
    "\n",
    "p_value = 2 * binom.cdf(min(above_hypothesized, below_hypothesized), n, .5)\n",
    "print(f\"P-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
